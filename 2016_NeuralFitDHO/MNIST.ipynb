{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import model_selection, metrics, datasets\n",
    "from neupy import algorithms, layers, environment\n",
    "import pickle\n",
    "environment.reproducible()\n",
    "environment.speedup()\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    mnist = datasets.fetch_mldata('MNIST original')\n",
    "    data = mnist.data\n",
    "\n",
    "    target_scaler = OneHotEncoder()\n",
    "    target = mnist.target.reshape((-1, 1))\n",
    "    target = target_scaler.fit_transform(target).todense()\n",
    "\n",
    "    n_samples = data.shape[0]\n",
    "    data = data.reshape((n_samples, 1, 28, 28))\n",
    "\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "        data.astype(np.float32),\n",
    "        target.astype(np.float32),\n",
    "        train_size=(6 / 7.)\n",
    "    )\n",
    "\n",
    "    mean = x_train.mean(axis=(0, 2, 3))\n",
    "    std = x_train.std(axis=(0, 2, 3))\n",
    "\n",
    "    #x_train -= mean\n",
    "    #x_train /= std\n",
    "    #x_test -= mean\n",
    "    #x_test /= std\n",
    "    x_train /= 255.0\n",
    "    x_test /= 255.0\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main information\n",
      "\n",
      "[ALGORITHM] Adadelta\n",
      "\n",
      "[OPTION] batch_size = 128\n",
      "[OPTION] verbose = True\n",
      "[OPTION] epoch_end_signal = None\n",
      "[OPTION] show_epoch = 1\n",
      "[OPTION] shuffle_data = True\n",
      "[OPTION] step = 1.0\n",
      "[OPTION] train_end_signal = None\n",
      "[OPTION] error = categorical_crossentropy\n",
      "[OPTION] addons = ['StepDecay']\n",
      "[OPTION] decay = 0.95\n",
      "[OPTION] epsilon = 1e-05\n",
      "[OPTION] reduction_freq = 8\n",
      "\n",
      "[THEANO] Initializing Theano variables and functions.\n",
      "[THEANO] Initialization finished successfully. It took 18.88 seconds\n",
      "\n",
      "Network's architecture\n",
      "\n",
      "--------------------------------------------------\n",
      "| #  | Input shape  | Layer type  | Output shape |\n",
      "--------------------------------------------------\n",
      "|  1 |  (1, 28, 28) |       Input |  (1, 28, 28) |\n",
      "|  2 |  (1, 28, 28) | Convolution | (32, 26, 26) |\n",
      "|  3 | (32, 26, 26) |   BatchNorm | (32, 26, 26) |\n",
      "|  4 | (32, 26, 26) |        Relu | (32, 26, 26) |\n",
      "|  5 | (32, 26, 26) | Convolution | (48, 24, 24) |\n",
      "|  6 | (48, 24, 24) |   BatchNorm | (48, 24, 24) |\n",
      "|  7 | (48, 24, 24) |        Relu | (48, 24, 24) |\n",
      "|  8 | (48, 24, 24) |  MaxPooling | (48, 12, 12) |\n",
      "|  9 | (48, 12, 12) | Convolution | (64, 10, 10) |\n",
      "| 10 | (64, 10, 10) |   BatchNorm | (64, 10, 10) |\n",
      "| 11 | (64, 10, 10) |        Relu | (64, 10, 10) |\n",
      "| 12 | (64, 10, 10) |  MaxPooling |   (64, 5, 5) |\n",
      "| 13 |   (64, 5, 5) |     Reshape |         1600 |\n",
      "| 14 |         1600 |      Linear |         1024 |\n",
      "| 15 |         1024 |   BatchNorm |         1024 |\n",
      "| 16 |         1024 |        Relu |         1024 |\n",
      "| 17 |         1024 |     Softmax |           10 |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "Time: 0:00:00 |N/A%|                           | ETA:  --:--:-- | error: ------"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\n",
      "Start training\n",
      "\n",
      "[TRAINING DATA] shapes: (60000, 1, 28, 28)\n",
      "[TEST DATA] shapes: (10000, 1, 28, 28)\n",
      "[TRAINING] Total epochs: 1\n",
      "\r\n",
      "---------------------------------------------------------\n",
      "|    Epoch    |  Train err  |  Valid err  |    Time     |\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time: 0:00:00 |N/A%|                                           | ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|           1 |    0.099958 |    0.063426 |       06:55 |\n",
      "---------------------------------------------------------\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       936\n",
      "          1       0.98      1.00      0.99      1163\n",
      "          2       0.98      0.99      0.98       982\n",
      "          3       1.00      0.99      0.99      1038\n",
      "          4       0.98      0.99      0.99       948\n",
      "          5       1.00      0.95      0.97       921\n",
      "          6       0.97      0.99      0.98      1013\n",
      "          7       0.99      0.98      0.98      1029\n",
      "          8       0.99      0.96      0.97       978\n",
      "          9       0.98      0.98      0.98       992\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n",
      "Validation accuracy: 98.20%\n"
     ]
    }
   ],
   "source": [
    "network = algorithms.Adadelta(\n",
    "    [\n",
    "        layers.Input((1, 28, 28)),\n",
    "\n",
    "        layers.Convolution((32, 3, 3)) > layers.BatchNorm() > layers.Relu(),\n",
    "        layers.Convolution((48, 3, 3)) > layers.BatchNorm() > layers.Relu(),\n",
    "        layers.MaxPooling((2, 2)),\n",
    "\n",
    "        layers.Convolution((64, 3, 3)) > layers.BatchNorm() > layers.Relu(),\n",
    "        layers.MaxPooling((2, 2)),\n",
    "\n",
    "        layers.Reshape(),\n",
    "        layers.Linear(1024) > layers.BatchNorm() > layers.Relu(),\n",
    "        layers.Softmax(10),\n",
    "    ],\n",
    "\n",
    "    # Using categorical cross-entropy as a loss function\n",
    "    error='categorical_crossentropy',\n",
    "\n",
    "    # Min-batch size\n",
    "    batch_size=128,\n",
    "\n",
    "    # Learning rate. We can allow high values\n",
    "    # since we are using Batch Normalization\n",
    "    step=1.0,\n",
    "\n",
    "    # Shows information about algorithm and\n",
    "    # training progress in terminal\n",
    "    verbose=True,\n",
    "\n",
    "    # Randomly shuffles training dataset before every epoch\n",
    "    shuffle_data=True,\n",
    "\n",
    "    # Step decay algorithm minimizes learning step\n",
    "    # monotonically after each iteration.\n",
    "    addons=[algorithms.StepDecay],\n",
    "    # Parameter controls step redution frequency. The higher\n",
    "    # the value the slower step parameter decreases.\n",
    "    reduction_freq=8,\n",
    ")\n",
    "\n",
    "# Shows networks architecture in terminal's output\n",
    "network.architecture()\n",
    "\n",
    "# Train for only two epochs\n",
    "network.train(x_train, y_train, x_test, y_test, epochs=1)\n",
    "\n",
    "y_predicted = network.predict(x_test).argmax(axis=1)\n",
    "y_test_labels = np.asarray(y_test.argmax(axis=1)).reshape(len(y_test))\n",
    "\n",
    "print(metrics.classification_report(y_test_labels, y_predicted))\n",
    "score = metrics.accuracy_score(y_test_labels, y_predicted)\n",
    "print(\"Validation accuracy: {:.2%}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"net.dump\", \"wb\")\n",
    "pickle.dump(network, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main information\n",
      "\n",
      "[ALGORITHM] Adadelta\n",
      "\n",
      "[OPTION] batch_size = 128\n",
      "[OPTION] verbose = True\n",
      "[OPTION] epoch_end_signal = None\n",
      "[OPTION] show_epoch = 1\n",
      "[OPTION] shuffle_data = True\n",
      "[OPTION] step = 1.0\n",
      "[OPTION] train_end_signal = None\n",
      "[OPTION] error = categorical_crossentropy\n",
      "[OPTION] addons = ['StepDecay']\n",
      "[OPTION] decay = 0.95\n",
      "[OPTION] epsilon = 1e-05\n",
      "[OPTION] reduction_freq = 8\n",
      "\n",
      "[THEANO] Initializing Theano variables and functions.\n",
      "[THEANO] Initialization finished successfully. It took 20.48 seconds\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "f = open(\"net.dump\", \"r\")\n",
    "network = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скорее всего это цифра  4\n",
      "Но может быть и  1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cap.set(15, 0.1)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2BGRA)\n",
    "    cv2.imshow('frame', rgb)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #newframe = cv2.resize(frame,(28,28))\n",
    "        #out = cv2.imwrite('capture.jpg', frame)\n",
    "        #newout = cv2.imwrite('newcapture.jpg', newframe)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.resize(gray,(28,28))\n",
    "        ret, gb = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "        gb = cv2.bitwise_not(gb)        \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "gb = gb/255\n",
    "M = network.predict(np.array([[gb]]))[0]\n",
    "args = M.argsort()[-2:]\n",
    "print \"Скорее всего это цифра \", args[1]\n",
    "print \"Но может быть и \", args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "def img_ready(filename):\n",
    "    im = io.imread(filename)\n",
    "    imc = rgb2gray(1-im)\n",
    "    imcb = imc>0.5\n",
    "    imr=resize(imcb, (28, 28), mode='reflect')\n",
    "    return imr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8e962e19cd3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "network.predict(np.array([[img]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.04910960e-03,   9.89098012e-01,   1.26404129e-05,\n",
       "         3.49185086e-07,   7.48948660e-03,   3.08556923e-06,\n",
       "         1.86622041e-04,   1.05273859e-04,   5.19283967e-05,\n",
       "         3.50924574e-06], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
