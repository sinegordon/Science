{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import model_selection, metrics, datasets\n",
    "from neupy import algorithms, layers, environment\n",
    "\n",
    "\n",
    "environment.reproducible()\n",
    "environment.speedup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main information\n",
      "\n",
      "[ALGORITHM] Adadelta\n",
      "\n",
      "[OPTION] batch_size = 128\n",
      "[OPTION] verbose = True\n",
      "[OPTION] epoch_end_signal = None\n",
      "[OPTION] show_epoch = 1\n",
      "[OPTION] shuffle_data = True\n",
      "[OPTION] step = 1.0\n",
      "[OPTION] train_end_signal = None\n",
      "[OPTION] error = categorical_crossentropy\n",
      "[OPTION] addons = ['StepDecay']\n",
      "[OPTION] decay = 0.95\n",
      "[OPTION] epsilon = 1e-05\n",
      "[OPTION] reduction_freq = 8\n",
      "\n",
      "[THEANO] Initializing Theano variables and functions.\n",
      "[THEANO] Initialization finished successfully. It took 11.43 seconds\n"
     ]
    }
   ],
   "source": [
    "nmax = 4\n",
    "\n",
    "def dhofun(x, nl, *p):\n",
    "    res = 0.0    \n",
    "    for i in xrange(nl):\n",
    "        A = p[3*i]\n",
    "        G = p[3*i+1]\n",
    "        E = p[3*i+2]\n",
    "        X2 = x**2\n",
    "        E2 = E*E\n",
    "        res += X2*E2*G*A/((X2 - E2)**2 + X2*G*G)\n",
    "    maxl = np.max(res)\n",
    "    return res/maxl\n",
    "\n",
    "def get_data(count):\n",
    "    \n",
    "    x = np.linspace(1, 10, 100)\n",
    "    x_train = np.zeros((count, 1, 1, 100))\n",
    "    x_test = np.zeros((100, 1, 1, 100))\n",
    "    y_train = np.zeros((count, nmax))\n",
    "    y_test = np.zeros((100, nmax))\n",
    "    p = np.zeros(3*nmax)\n",
    "    for i in range(count):\n",
    "        nl = np.random.randint(1, nmax+1)\n",
    "        for k in range(nl):\n",
    "            p[3*k] = np.random.uniform(0, 1)\n",
    "            p[3*k+1] = np.random.uniform(0, 5)\n",
    "            p[3*k+2] = np.random.uniform(1, 10)\n",
    "        x_train[i, 0, 0, :] = dhofun(x, nl, *p)\n",
    "        y_train[i, nl-1] = 1\n",
    "\n",
    "    for i in range(100):\n",
    "        nl = np.random.randint(1, nmax+1)\n",
    "        for k in range(nl):\n",
    "            p[3*k] = np.random.uniform(0, 1)\n",
    "            p[3*k+1] = np.random.uniform(0, 5)\n",
    "            p[3*k+2] = np.random.uniform(1, 10)\n",
    "        x_test[i, 0, 0, :] = dhofun(x, nl, *p)\n",
    "        y_test[i, nl-1] = 1\n",
    "               \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "network = algorithms.Adadelta(\n",
    "    [\n",
    "        layers.Input((1, 1, 100)),\n",
    "\n",
    "        layers.Convolution((16, 1, 7)) > layers.BatchNorm() > layers.Relu(),\n",
    "        layers.MaxPooling((1, 3)),\n",
    "        layers.Convolution((8, 1, 5)) > layers.BatchNorm() > layers.Relu(),\n",
    "        layers.MaxPooling((1, 2)),\n",
    "        layers.Convolution((4, 1, 3)) > layers.BatchNorm() > layers.Relu(),\n",
    "        layers.MaxPooling((1, 2)),\n",
    "\n",
    "        layers.Reshape(),\n",
    "        layers.Linear(1024) > layers.BatchNorm() > layers.Relu(),\n",
    "        layers.Softmax(nmax),\n",
    "    ],\n",
    "\n",
    "    # Using categorical cross-entropy as a loss function\n",
    "    error='categorical_crossentropy',\n",
    "\n",
    "    # Min-batch size\n",
    "    batch_size=128,\n",
    "\n",
    "    # Learning rate. We can allow high values\n",
    "    # since we are using Batch Normalization\n",
    "    step=1.0,\n",
    "\n",
    "    # Shows information about algorithm and\n",
    "    # training progress in terminal\n",
    "    verbose=True,\n",
    "\n",
    "    # Randomly shuffles training dataset before every epoch\n",
    "    shuffle_data=True,\n",
    "\n",
    "    # Step decay algorithm minimizes learning step\n",
    "    # monotonically after each iteration.\n",
    "    addons=[algorithms.StepDecay],\n",
    "    # Parameter controls step redution frequency. The higher\n",
    "    # the value the slower step parameter decreases.\n",
    "    reduction_freq=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network's architecture\n",
      "\n",
      "-------------------------------------------------\n",
      "| #  | Input shape | Layer Type  | Output shape |\n",
      "-------------------------------------------------\n",
      "| 1  | (1, 1, 100) | Input       | (1, 1, 100)  |\n",
      "| 2  | (1, 1, 100) | Convolution | (16, 1, 94)  |\n",
      "| 3  | (16, 1, 94) | BatchNorm   | (16, 1, 94)  |\n",
      "| 4  | (16, 1, 94) | Relu        | (16, 1, 94)  |\n",
      "| 5  | (16, 1, 94) | MaxPooling  | (16, 1, 31)  |\n",
      "| 6  | (16, 1, 31) | Convolution | (8, 1, 27)   |\n",
      "| 7  | (8, 1, 27)  | BatchNorm   | (8, 1, 27)   |\n",
      "| 8  | (8, 1, 27)  | Relu        | (8, 1, 27)   |\n",
      "| 9  | (8, 1, 27)  | MaxPooling  | (8, 1, 13)   |\n",
      "| 10 | (8, 1, 13)  | Convolution | (4, 1, 11)   |\n",
      "| 11 | (4, 1, 11)  | BatchNorm   | (4, 1, 11)   |\n",
      "| 12 | (4, 1, 11)  | Relu        | (4, 1, 11)   |\n",
      "| 13 | (4, 1, 11)  | MaxPooling  | (4, 1, 5)    |\n",
      "| 14 | (4, 1, 5)   | Reshape     | 20           |\n",
      "| 15 | 20          | Linear      | 1024         |\n",
      "| 16 | 1024        | BatchNorm   | 1024         |\n",
      "| 17 | 1024        | Relu        | 1024         |\n",
      "| 18 | 1024        | Softmax     | 4            |\n",
      "-------------------------------------------------\n",
      "\n",
      "Generate data...\n",
      "Done generate data.\n"
     ]
    }
   ],
   "source": [
    "# Shows networks architecture in terminal's output\n",
    "network.architecture()\n",
    "\n",
    "print(\"Generate data...\")\n",
    "x_train, x_test, y_train, y_test = get_data(100000)\n",
    "print(\"Done generate data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training\n",
      "\n",
      "[TRAINING DATA] shapes: (100000, 1, 1, 100)\n",
      "[TEST DATA] shapes: (100, 1, 1, 100)\n",
      "[TRAINING] Total epochs: 4\n",
      "\n",
      "------------------------------------------------\n",
      "| Epoch # | Train err | Valid err | Time       |\n",
      "------------------------------------------------\n",
      "| 1       | 1.334     | 1.403     | 00:00:18   |                                       \n",
      "| 2       | 1.025     | 1.161     | 00:00:18   |                                       \n",
      "| 3       | 0.9855    | 1.076     | 00:00:18   |                                       \n",
      "| 4       | 0.9622    | 1.129     | 00:00:18   |                                       \n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train for only two epochs\n",
    "network.train(x_train, y_train, x_test, y_test, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.95      0.73        21\n",
      "          1       0.37      0.59      0.46        32\n",
      "          2       0.00      0.00      0.00        20\n",
      "          3       0.64      0.33      0.44        27\n",
      "\n",
      "avg / total       0.42      0.48      0.42       100\n",
      "\n",
      "Validation accuracy: 48.00%\n"
     ]
    }
   ],
   "source": [
    "y_predicted = network.predict(x_test).argmax(axis=1)\n",
    "y_test_labels = np.asarray(y_test.argmax(axis=1)).reshape(len(y_test))\n",
    "\n",
    "print(metrics.classification_report(y_test_labels, y_predicted))\n",
    "score = metrics.accuracy_score(y_test_labels, y_predicted)\n",
    "print(\"Validation accuracy: {:.2%}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
